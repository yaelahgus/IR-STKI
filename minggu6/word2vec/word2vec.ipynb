{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a0021e-7347-4b45-b4ac-dd1629545e24",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57a77d-582c-416d-985f-9947c455dcf6",
   "metadata": {},
   "source": [
    "Word2vec adalah suatu metode untuk merepresentasikan setiap kata di dalam konteks sebagai vektor dengan N demensi. Dalam mempresentasikan suatu kata, Word2Vec mengimplementasi neural network untuk menghitung contextual and semantic similarity (kesamaan kontekstual dan semantik) dari setiap kata (inputan) yang berbentuk one-hot encoded vectors.\n",
    "\n",
    "Hasil dari contextual and semantic similarity ini dapat merepresentasikan relasi suatu kata dengan kata lainnya, misalnya relasi antara ‘Male — Female’, relasi pada ‘Verb tense’, dan bahkan relasi pada ‘Country — Capital’ , seperti yang diilustrasikan pada gambar dibawah ini:\n",
    "\n",
    "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zhyMgHgIlGNtPHuuaIom8g.png)\n",
    "\n",
    "Hasil dari relasi-relasi tersebut menjadi referensi dalam merepresentasikan suatu kata menjadi vektor. misalnya representasi vektor[queen] didapatkan dari vektor[king] yang dikurang vektor[man] kemudian ditambah vektor[woman].\n",
    "\n",
    "vektor[queen] = vektor[king] - vektor[man] + vektor[woman]“the best revenge is massive success”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31087b-6eb5-4272-8160-bd6282eeeb8e",
   "metadata": {},
   "source": [
    "#### Model Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e607d1-4a9c-4652-90d8-3923e4461c33",
   "metadata": {},
   "source": [
    "Word2Vec memiliki 2 model yaitu Continuous Bag-of-Word (CBOW) dan Skip-Gram. Arsitektur CBOW dan Skip-Gram dapat dilihat pada gambar dibawah ini \n",
    "\n",
    "![title](https://miro.medium.com/v2/resize:fit:1326/format:webp/1*S2sg7Hyi8meTDICbT4dswg.png)\n",
    "\n",
    "#### Skip-gram\n",
    "\n",
    "Skip-Gram merupakan model yang diperkenalkan oleh Mikolov et al. Ilustrasi feeding forward Skip-Gram dengan windows (jarak antara kata-kata konteks dengan posisi kata yang menjadi inputan) = 2 dapat dilihat pada gambar dibawah ini :\n",
    "\n",
    "![title](https://miro.medium.com/v2/resize:fit:1164/format:webp/1*3Q7oUf0MqkBCd5Mg79A3gg.jpeg)\n",
    "\n",
    "Secara Arsitektur Skip-Gram menggunakan current word (sebagai input) untuk memprediksi konteks (sebagai target) disekitarnya, dimana Skip-Gram akan mempelajari distribusi probabilitas dari kata-kata didalam konteks dengan windows yang telah di tentukan. Misal konteks yang digunakan saat ini adalah “the best revenge is massive success” dengan nilai windows = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f86a5e-e46b-4192-bc26-bf539903ad53",
   "metadata": {},
   "source": [
    "#### “the best revenge is massive success”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ad573-3aa9-443e-843f-b18dea2bcc46",
   "metadata": {
    "tags": []
   },
   "source": [
    "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NhFRU2ONdXKgL5E-PkfEEg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226de69-9690-4341-bfb2-dfbebc134889",
   "metadata": {},
   "source": [
    "Untuk merepresentasikan konteks kedalam arsitektur Skip-Gram, maka kita harus merubah setiap kata menjadi one-hot encoded vectors."
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb4786ec-354d-4b1f-b1a5-6d3142a1e5e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "the      = [1,0,0,0,0,0]\n",
    "best     = [0,1,0,0,0,0]\n",
    "revenge  = [0,0,1,0,0,0]\n",
    "is       = [0,0,0,1,0,0]\n",
    "massive  = [0,0,0,0,1,0]\n",
    "success  = [0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d6a073-fc47-47ed-b341-e3e01fa27df9",
   "metadata": {},
   "source": [
    "ilustrasi forward-backward training Skip-Gram dengan nilai random pada weight (W dan W`), dengan w(t) = “revenge” sebagai input, dan w(t - 2) = “the”, w(t - 1) = “best”, w(t + 1) = “is”, w(t + 2) = “massive” sebagai target dapat dilihat pada gambar dibawah ini :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd391156-55aa-4abe-82a3-183ce5227325",
   "metadata": {},
   "source": [
    "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xSSn7oxwaKDQJYVe2SdfVA.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad2bc0e-6474-447c-ba22-88d0c1f856e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0]\n",
      "[[0.37454012 0.95071431 0.73199394]\n",
      " [0.59865848 0.15601864 0.15599452]\n",
      " [0.05808361 0.86617615 0.60111501]\n",
      " [0.70807258 0.02058449 0.96990985]\n",
      " [0.83244264 0.21233911 0.18182497]\n",
      " [0.18340451 0.30424224 0.52475643]]\n",
      "[0.05808361 0.86617615 0.60111501]\n",
      "[[0.43194502 0.29122914 0.61185289 0.13949386 0.29214465 0.36636184]\n",
      " [0.45606998 0.78517596 0.19967378 0.51423444 0.59241457 0.04645041]\n",
      " [0.60754485 0.17052412 0.06505159 0.94888554 0.96563203 0.80839735]]\n",
      "[0.7853302  0.79952094 0.24759478 1.02390925 1.1105601  0.54745364]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "v_revenge = np.array([0,0,1,0,0,0]) #\"revenge\"\n",
    "print(v_revenge)\n",
    "#array([0, 0, 1, 0, 0, 0])\n",
    "weight = np.random.random_sample((6,3))\n",
    "print(weight)\n",
    "# array([[ 0.43194502,  0.29122914,  0.61185289],\n",
    "#        [ 0.13949386,  0.29214465,  0.36636184],\n",
    "#        [ 0.45606998,  0.78517596,  0.19967378],\n",
    "#        [ 0.51423444,  0.59241457,  0.04645041],\n",
    "#        [ 0.60754485,  0.17052412,  0.06505159],\n",
    "#        [ 0.94888554,  0.96563203,  0.80839735]])\n",
    "\n",
    "hidden_layer_sg = np.dot(v_revenge,weight)\n",
    "print(hidden_layer_sg)\n",
    "#array([ 0.45606998,  0.78517596,  0.19967378])\n",
    "weight_prime = np.random.random_sample((3,6))\n",
    "print(weight_prime)\n",
    "#array([[ 0.30461377, 0.09767211, 0.68423303, 0.44015249, 0.12203823, 0.49517691],\n",
    "       # [ 0.03438852, 0.9093204, 0.25877998, 0.66252228, 0.31171108,      0.52006802],\n",
    "       # [ 0.54671028, 0.18485446, 0.96958463, 0.77513282, 0.93949894,    0.89482735]])\n",
    "o_the = np.dot(hidden_layer_sg, weight_prime)\n",
    "print(o_the)\n",
    "#array([ 0.27508995, 0.79543243, 0.7088466, 0.87571061, 0.48799933, 0.8128538 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae482d30-75e6-4311-ab53-008967927329",
   "metadata": {},
   "source": [
    "Setelah output didapatkan, perlu dilakukan perhitungan nilai error dengan metode cross entropy (target - output). Tahap setelah perhitungan nilai error adalah backprogation, dengan menghitung gradien lost function terhadap semua parameter yang ada dengan cara mencari partial derivative. Pada tahap backprogation terjadi proses update parameter, yaitu mengurangi atau menambahkan weight (W dan W`) lama dengan nilai gradient yang sudah didapatkan (Gradient Descent) hingga tercapai nilai minimum error pada cross entropy. Saya akan membahas detail implementasi perhitungan Skip-Gram pada artikel Word2Vec Part 3 (Implementasi Skip-Gram)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a494d3f-f074-4fcc-8022-ff76f3f44a0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Continuous Bag-of-Word (CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f04e6a-ff11-4b07-9fb4-23da5d1b01d0",
   "metadata": {},
   "source": [
    "Ilustrasi feeding forward training CBOW dengan nilai windows = 2 dapat dilihat pada gambar dibawah ini :\n",
    "\n",
    "![title](https://miro.medium.com/v2/resize:fit:1268/format:webp/1*czycrB3Uz2eoplRUZImbsw.jpeg)\n",
    "\n",
    "CBOW merupakan model yang memprediksi current word (sebagai target) dari konteks (sebagai input) di sekitarnya[4]. bisa dikatakan bahwa CBOW merupakan kebalikan dari Skip-Gram, dimana CBOW pun akan mempelajari distribusi probabilitas dari konteks dengan windows yang telah di tentukan. konteks yang digunakan serupa dengan konteks pada ilustrasi implementasi Skip-Gram sehingga menggunakan one-hot encoded vectors yang serupa.\n",
    "\n",
    "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0uSEgZQEsaUCZYm_l0N0Lw.jpeg)\n",
    "\n",
    "ilustrasi forward-backward training CBOW dengan nilai random pada weight (W dan W`), dengan w(t - 2) = “the”, w(t - 1) = “best”, w(t + 1) = “is”, w(t + 2) = “massive” sebagai inputan, dan w(t) = “revenge” sebagai target dapat dilihat pada gambar dibawah ini :\n",
    "\n",
    "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LgVn0c-jcQcwbKKOUNIPUQ.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c4f6d4b-aa1c-48c1-b664-dd955aca6630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0]\n",
      "[0.05808361 0.86617615 0.60111501]\n",
      "[0.7853302  0.79952094 0.24759478 1.02390925 1.1105601  0.54745364]\n"
     ]
    }
   ],
   "source": [
    "v_the = np.array([0,0,1,0,0,0]) #\"the\"\n",
    "print(v_the)\n",
    "#array([1, 0, 0, 0, 0, 0])\n",
    "#weight = menggunakan weight yang sama dengan ilustrasi pada Skip-Gram\n",
    "hidden_layer_cbow = np.dot(v_the,weight)\n",
    "print(hidden_layer_cbow)\n",
    "#array([0.43194502, 0.29122914, 0.61185289])\n",
    "#weight_prime = menggunakan weight_prime yang sama dengan ilustrasi pada Skip-Gram\n",
    "o_revenge = np.dot(hidden_layer_cbow, weight_prime)\n",
    "print(o_revenge)\n",
    "#array([0.47609761, 0.42011332, 0.96415848, 0.85733473, 0.7183283, 0.91285087])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a341e-3963-4677-aa3a-56f6e892a3fb",
   "metadata": {},
   "source": [
    "Setelah output didapatkan, maka tahap selanjutnya serupa seperti tahap dan proses yang ada pada backprogation Skip-Gram hingga tercapai nilai minimum error pada cross entropy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
